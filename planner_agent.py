from typing import Optional
import httpx
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel,Field
from langchain.output_parsers import PydanticOutputParser


class CodeFormat(BaseModel):
    """
    Represents the structure of code output generated by the LLM via LangChain.

    This class is designed to work with LangChain's PydanticOutputParser for structured output
    from language models in the Kaggle problem-solving pipeline.

    Attributes:
        imports (str): A string containing all necessary import statements for the solution.
        code (str): The main body of code implementing the solution for the current task.
        description (str): A brief explanation of what the code does and how it contributes
            to solving the Kaggle problem.

    Usage:
        This class is typically used with LangChain's PydanticOutputParser to structure
        the output of an LLM when generating code for Kaggle problems.

    Example:
        from langchain.output_parsers import PydanticOutputParser
        from langchain.prompts import PromptTemplate
        
        parser = PydanticOutputParser(pydantic_object=CodeFormat)
        
        prompt = PromptTemplate(
            template="Generate Python code for {task}.\n{format_instructions}\n",
            input_variables=["task"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        _input = prompt.format_prompt(task="reading a CSV file")
        output = llm(_input.to_string())
        code_output = parser.parse(output)
    """

    imports: Optional[str] = Field(description="Imports required for the solution.")
    code: str = Field(description="Code for the solution")
    description: Optional[str] = Field(description="Description for the solution.")

class KaggleProblemPlanner:
    def __init__(self,config):
        proxy=httpx.Client(proxy="http://127.0.0.1:2081")
        self.config = config
        self.llm = ChatOpenAI(model="gpt-3.5-turbo",http_client=proxy)
        self.planner_prompt = ChatPromptTemplate.from_template("""
        You are an AI assistant tasked with solving a Kaggle machine learning problem.
        Given the problem description and current state, create or update a plan to solve the problem.

        Problem Description:
        {problem_description}

        Current State:
        {state}

        Your task is to:
        1. Analyze the problem description and current state.
        2. Create or update a plan of tasks to solve the Kaggle problem.
        3. Ensure the plan covers all necessary steps: EDA, preprocessing, feature engineering, model selection, training, and evaluation.

        Respond with a list of planned tasks, each on a new line.
        """)
        
        self.code_generator_prompt = ChatPromptTemplate.from_template("""
        You are an AI assistant tasked with generating Python code to solve a Kaggle machine learning problem.
        Given the current task and project state, generate the necessary code.

        Problem Description:
        {problem_description}

        Current Task: {current_task}

        Project State:
        {state}

        Your task is to:
        1. Generate Python code to accomplish the current task.
        2. Ensure the code is compatible with the Kaggle notebook environment.
        3. Use pandas, scikit-learn, and other common ML libraries as needed.
        4. Include comments to explain key steps.

        Respond with only the Python code, without any additional explanation.
        
        this is output_format_instructions you must provide in the this case:
        
        {format_instructions}
        
        """)

    def plan(self, state):
        response = self.llm.invoke(self.planner_prompt.format_messages(
            problem_description=state.problem_description,
            state=str(state.__dict__)
        ),config=self.config)
        return response.content.strip().split("\n")

    def generate_code(self, state):
        output_parser = PydanticOutputParser(pydantic_object = CodeFormat)
        format_instructions=output_parser.get_format_instructions()
        response = (self.code_generator_prompt|self.llm|output_parser).invoke({
            'problem_description':state.problem_description,
            'current_task':state.current_task,
            'state':str(state.__dict__),
            "format_instructions":format_instructions
        }
        ,config=self.config)
        return response
